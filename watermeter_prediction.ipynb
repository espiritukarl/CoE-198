{"cells":[{"cell_type":"markdown","source":["# **PREREQUISITES**"],"metadata":{"id":"Q91WsmJYPVCq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CdJVBFSAGNJ"},"outputs":[],"source":["# This code is from this website: https://pysource.com/2021/08/10/train-mask-r-cnn-for-image-segmentation-online-free-gpu/\n","\n","%tensorflow_version 1.x\n","!pip install --upgrade h5py==2.10.0\n","!wget https://pysource.com/extra_files/Mask_RCNN_basic_1.zip\n","!unzip Mask_RCNN_basic_1.zip\n","import sys\n","sys.path.append(\"/content/Mask_RCNN/mrcnn\")\n","from m_rcnn import *\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykjL5JmOmoWh"},"outputs":[],"source":["# For MQTT Protocol Functions\n","\n","pip install paho-mqtt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBMpPPQWAWpj"},"outputs":[],"source":["# Required libraries for the project\n","\n","import cv2\n","import numpy as np\n","from mrcnn.visualize import random_colors, get_mask_contours, draw_mask\n","from google.colab.patches import cv2_imshow\n","from PIL import Image\n","import glob\n","import os\n","import time\n","import tensorflow as tf\n","import torch\n","from torchvision import datasets, models, transforms\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from keras.models import load_model\n","from keras.preprocessing import image\n","import paho.mqtt.client as mqttclient\n","import json\n","from skimage import io"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jtqe6s53AZ3y"},"outputs":[],"source":["# Mount your google drive here\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# **CHANGE CODE HERE**"],"metadata":{"id":"M4iCfB-gPneM"}},{"cell_type":"markdown","source":["The main directory should look like this:\n","\n","*root_folder/*\n","\n","  │\n","\n","*├──  models/*\n","\n","*├──  input_image/*\n","\n","*├──  roi/*\n","\n","*├──  masked_digits/*\n","\n","*├──  cropped_digits/*"],"metadata":{"id":"8Pvwsu0bxmBU"}},{"cell_type":"code","source":["# CHANGE THE VALUE OF \"folder_path\" TO YOUR CORRECT DIRECTORY\n","folder_path = \"/content/drive/MyDrive/Documentation Files/(4)Step-by-step/prediction_files/\"\n","\n","# NO NEED TO CHANGE THESE VALUES\n","models_path = folder_path + \"models/\"                 # This directory will store the three deep learning models\n","input_image_path = folder_path + \"input_image/\"       # This directory will store the input images taken by the ESP32-CAM\n","roi_path = folder_path + \"roi/\"                       # This directory will store the ROI image file from the ROI Detection model\n","masked_digits_path = folder_path + \"masked_digits/\"   # This directory will store the masked digit image files from the Digit Detection Model\n","cropped_digits_path = folder_path + \"cropped_digits/\" # This directory will store the cropped individual image files"],"metadata":{"id":"CRWrk3vJ4j8-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **MAIN CODE**"],"metadata":{"id":"3sT0LkJyDk03"}},{"cell_type":"markdown","source":["The code below loads the models from the \"*root_folder/models/*\" path."],"metadata":{"id":"xlx7O57A0Rom"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMOQlRL3B3zN"},"outputs":[],"source":["test_model_ROI, inference_config_ROI = load_inference_model(1, models_path + \"ROI_detection_model.h5\")          # Loads the ROI Detection Model \n","test_model_digits, inference_config_digits = load_inference_model(1, models_path + \"digit_detection_model.h5\")  # Loads the Digit Detection Model \n","model_reading = models.resnext50_32x4d(pretrained=True)                                       \n","num_ftrs = model_reading.fc.in_features\n","model_reading.fc = nn.Linear(num_ftrs, 10)\n","checkpoint = torch.load(models_path + \"digit_reading_model.pt\")                                                 # Loads the Digit Reading Model\n","model_reading.load_state_dict(checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXoK4sSfBYYV"},"outputs":[],"source":["initial_checker = 0\n","\n","while(1):\n","  for filename in os.listdir(input_image_path):\n","    print(input_image_path + filename)\n","\n","  # Get the input image from the input_image_path  \n","  img = cv2.imread(input_image_path + filename)\n","  # Remove the image so that only one image will be at the directory at a time\n","  # You can copy the image to another directory if you wish\n","  os.remove(input_image_path + filename)\n","\n","  cv2_imshow(img)\n","  # Get the ROI of the input image\n","  get_ROI(img)\n","  time.sleep(0.75)\n","  ROI = cv2.imread(roi_path + \"ROI.png\")\n","  cv2_imshow(ROI)\n","\n","  # Get the individual image files from the ROI\n","  get_digits(ROI)\n","\n","  # Compose the string of the actual reading of the water meter\n","  actual_reading = \"\"\n","\n","  # Iterate throught the cropped_digits_path and predict each image\n","  for filename in os.listdir(cropped_digits_path):\n","    image = cv2.imread(cropped_digits_path + filename)\n","    cv2_imshow(image)\n","    model_reading.eval()\n","    with torch.no_grad():\n","      prediction = predict_image(cropped_digits_path + filename)\n","      print(\"Predicted Class: \",prediction)\n","    actual_reading += str(prediction)\n","    os.remove(cropped_digits_path + filename)\n","\n","\n","  print(\"Predicted watermeter reading is \" + str(int(actual_reading)))\n","\n","  # Check if the image is the intitial image and set the values of the bill accordingly\n","  if(initial_checker == 0):\n","    initial_reading = int(actual_reading)\n","    final_reading = int(actual_reading)\n","    basic_charge = 0\n","    FCDA = 0\n","    environmental_charge = 0\n","    sewer_charge = 0\n","    vat = 0 \n","    before_tax = 0\n","    total_bill = 0\n","    initial_checker = 1\n","\n","  else:\n","    final_reading = int(actual_reading)\n","\n","  # Get the bill details using these variables\n","  consumption, basic_charge, FCDA, environmental_charge, sewer_charge, vat, before_tax, total_bill = get_bill()\n","  # Set up the MQTT_MSG using json.dumps() containing the bill details\n","  MQTT_MSG = json.dumps({\"payload_fields\": {\"reading\": int(actual_reading),\n","                                            \"basic charge\": int(basic_charge),\n","                                            \"FCDA\": int(FCDA),\n","                                            \"Environmental Charge\": int(environmental_charge),\n","                                            \"Sewer Charge\": int(sewer_charge),\n","                                            \"VAT Charge\": int(vat),\n","                                            \"Before TAX\": int(before_tax),\n","                                            \"bill\": int(total_bill)\n","                                            }});\n","  # Connect to the MQTT Broker                                          \n","  MQTT_connect(MQTT_MSG)\n","\n","  # Set the time you want to wait. In this case it is a 30 second wait before the next reading\n","  time.sleep(30) "]},{"cell_type":"markdown","source":["# **FUNCTIONS**"],"metadata":{"id":"1GBUXQ3_Dek9"}},{"cell_type":"markdown","source":["`get_ROI(img)` gets the ROI from an input image using the ROI Detection Model\n","\n","Once the ROI is obtained, the ROI image file in png will be saved to the \"*root_folder/roi/*\" path as \"*ROI.png*\"\n","\n","**Parameters**\n","\n","-`img` - image file from `cv2.imread()` function (This will be  the image of the whole water meter)\n"],"metadata":{"id":"HeaT9WvN2qGz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6uQnL1PAw1u"},"outputs":[],"source":["def get_ROI(img): # GETS THE ROI USING ROI_detection_model.h5 \n","  global masked_image\n","  try:\n","    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  except:\n","    print(\"error\")\n","    total_counter -= 1\n","  else:\n","  \n","    # Detect results\n","    r = test_model_ROI.detect([image])[0]\n","\n","    object_count = len(r[\"class_ids\"])\n","    colors = random_colors(50)\n","    for i in range(object_count):\n","        # 1. Mask\n","        mask = r[\"masks\"][:, :, i]\n","        contours = get_mask_contours(mask)\n","        for cnt in contours:\n","            mask = np.zeros(img.shape, dtype=np.uint8)\n","            cv2.fillPoly(mask, pts=[cnt], color=(255, 255, 255))\n","            masked_image = cv2.bitwise_and(img, mask)\n","\n","    # Make mask transparent\n","    try:\n","      tmp = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n","    except:\n","      print(\"error\")\n","    else:\n","      _,alpha = cv2.threshold(tmp,0,255,cv2.THRESH_BINARY)\n","      b, g, r = cv2.split(masked_image)\n","      rgba = [b,g,r, alpha]\n","      masked_tr = cv2.merge(rgba,4)\n","      idx = np.where(masked_tr[: ,: , 3] > 0)\n","      x0, y0, x1, y1 = idx[1].min(), idx[0].min(), idx[1].max(), idx[0].max()\n","      out = Image.fromarray(masked_tr[y0: y1 + 1, x0: x1 + 1,: ])\n","    \n","      out.save(roi_path + \"ROI.png\")"]},{"cell_type":"markdown","source":["`get_digits(img)` almost does the same thing as `get_ROI(img)` except this one extends its functionality by doing the process multiple times to get the masks of each individual digit in the ROI.\n","\n","\n","Once the each masked digit is obtained, the individual image files in png will be saved to the \"*root_folder/masked_digits/*\" path. Furthermore, the masked digits will be cropped and stored to the \"*root_folder/cropped_digits/*\" path.\n","\n","**Parameters**\n","\n","-`img` - ROI image file from `get_ROI(img)` function (This will be read from the the \"*root_folder/roi/*\" folder using `cv2.imread()`) \n"],"metadata":{"id":"NLL1spvB8oV6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zB6NquXvEmCh"},"outputs":[],"source":["def get_digits(img): # EXTRACTS THE DIGTS FROM THE MASKED DIGIT IMAGES\n","  global masked_image\n","  global number\n","  try:\n","    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  except:\n","    print(\"error\")\n","    total_counter -= 1\n","  else:\n","    coordinates = []\n","\n","    # Detect results\n","    r = test_model_digits.detect([image])[0]\n","\n","    object_count = len(r[\"class_ids\"])\n","    colors = random_colors(50)\n","    for i in range(object_count):\n","        # 1. Mask\n","        mask = r[\"masks\"][:, :, i]\n","        contours = get_mask_contours(mask)\n","        #print(type(mask))\n","        for cnt in contours:\n","            #cv2.polylines(img, [cnt], True, colors[i], 2)\n","            mask = np.zeros(img.shape, dtype=np.uint8)\n","            cv2.fillPoly(mask, pts=[cnt], color=(255, 255, 255))\n","            img_w_mask = draw_mask(img, [cnt], colors[i])\n","            masked_image = cv2.bitwise_and(img, mask)\n","            x_coor = find_nearest_white(mask, TARGET)\n","            coordinates.append(int(x_coor[1]))\n","        cv2.imwrite(masked_digits_path + str(x_coor[1]) + '.png', masked_image) \n","\n","    number = 0\n","    for filename in sorted(coordinates):\n","        masked_image = cv2.imread(masked_digits_path + str(filename) + \".png\")\n","        #cv2_imshow(masked_image)\n","        #print(filename)\n","        try:\n","          tmp = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n","        except:\n","          print(\"error\")\n","        else:\n","          _,alpha = cv2.threshold(tmp,0,255,cv2.THRESH_BINARY)\n","          b, g, r = cv2.split(masked_image)\n","          rgba = [b,g,r, alpha]\n","          masked_tr = cv2.merge(rgba,4)\n","\n","          idx = np.where(masked_tr[: ,: , 3] > 0)\n","\n","          x0, y0, x1, y1 = idx[1].min(), idx[0].min(), idx[1].max(), idx[0].max()\n"," \n","          out = Image.fromarray(masked_tr[y0: y1 + 1, x0: x1 + 1,: ])\n","\n","          out.save(cropped_digits_path + 'img({}).png'.format(number))\n","          #out.save('/content/drive/MyDrive/Results/img({}).png'.format(number))\n","          number = number + 1\n","          os.remove(masked_digits_path + str(filename) + \".png\")\n"]},{"cell_type":"markdown","source":["`find_nearest_white(img, target) ` finds the coordinates of the image with respect to the x axis. This will serve as indicators for the ordering of the digits from left to right for the `get_digits(img)` function.\n","\n","**Parameters**\n","\n","-`img` - the masked digit image file inside the `get_digits(img)` function\n","\n","-`target` - a non-zero pixel in the image\n","\n","**Returns**\n","\n","-coordinates of a corresponding nonzero pixel"],"metadata":{"id":"JUvcHHg05r98"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-ZSWt22D624"},"outputs":[],"source":["TARGET = (255,255) # ORDERS THE DIGITS CORRECTLY\n","def find_nearest_white(img, target):\n","\n","    nonzero = np.argwhere(img == 255)\n","    distances = np.sqrt((nonzero[:,0] - TARGET[0]) ** 2 + (nonzero[:,1] - TARGET[1]) ** 2)\n","    nearest_index = np.argmin(distances)\n","    return nonzero[nearest_index]"]},{"cell_type":"markdown","source":["`predict_image(image_path)` is a function that returns the index of the most likely value of the digit image file based on a class label from 0 to 9.\n","\n","**Parameters**\n","\n","-`image_path` - path of the input image \n","\n","\n","**Returns**\n","\n","-index of the class label which is from 0 to 9."],"metadata":{"id":"RvYO2zgh-FXv"}},{"cell_type":"code","source":["def predict_image(image_path): # PREDICTS THE IMAGE USING digit_reading_model.pt\n","  transformation = transforms.Compose([\n","      transforms.ToPILImage(),                                 \n","      transforms.Resize((32,32)),\n","      #transforms.RandomHorizontalFlip(),\n","      transforms.ToTensor(),\n","      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","      ])\n","  image_tensor = transformation(image).float()\n","  image_tensor = image_tensor.unsqueeze_(0)\n","\n","  if torch.cuda.is_available():\n","      image_tensor.cuda()\n","\n","  #input = Variable(image_tensor)\n","  output = model_reading(image_tensor)\n","  #print(output)\n","  index = output.data.numpy().argmax()\n","  return index"],"metadata":{"id":"3lsssC3DQfJd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`MQTT_connect(MQTT_MSG)` is a function that connects to a MQTT broker\n","\n","**Parameters**\n","\n","-`MQTT_MSG` - json string from a Python object using `json.dumps()`. This will contain the values that you want to display on the MQTT broker.\n"],"metadata":{"id":"_K4bDOCOAOYJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5tTXKRMhdda"},"outputs":[],"source":["def MQTT_connect(MQTT_MSG): # ESTABLISHES CONNECTION TO THE MQTT BROKER (things.ph)\n","  def on_connect(client, usedata, flags, rc):\n","    if rc == 0:\n","      #print(\"Client is connected\")\n","      global connected\n","      connected = True\n","    else:\n","      print(\"Connection failed.\")\n","\n","\n","  connected = False\n","  \n","  # EDIT THE VALUES TO CORRECTLY CONNECT TO THE MQTT BROKER YOU ARE USING\n","  broker_address = \"mqtt.things.ph\"\n","  port = 1883\n","  user = \"61b057b73bc1a3388183e64c\"\n","  password = \"Kfq3BA5tH3zCVkXpP3mcFNlI\"\n","  ##############\n","\n","  client = mqttclient.Client(\"MQTT\")\n","  client.username_pw_set(user, password=password)\n","  client.on_connect = on_connect\n","  client.connect(broker_address, port=port)\n","  client.loop_start()\n","  #while connected != True:\n","  #  time.sleep(0.2)\n","  client.publish(\"mqtt/watermeter\", MQTT_MSG)"]},{"cell_type":"markdown","source":["`get_bill()` function calculates the estimated bill using the *initial_reading* and *final_reading* values.\n","\n","\n","**Returns**\n","\n","-the bill breakdown such as *basic_charge, FCDA, environmental_charge, sewer_charge, vat, before_tax, total_bill*"],"metadata":{"id":"HF16Bda0BKTA"}},{"cell_type":"code","source":["def get_bill(): # CALCULATES THE ESTIMATED BILL\n","\n","  # MANILA WATER\n","  # bill_lessthan10 = 63.16\n","  # bill_first10 = 111.27\n","  # bill_next10 = 13.56\n","  # bill_next20_1 = 25.71\n","  # bill_next20_2 = 33.89\n","  # bill_next20_3 = 39.58\n","  # bill_next20_4 = 41.49\n","  # bill_next50_1 = 43.34\n","  # bill_next50_2 = 45.2\n","  # bill_over200 = 47.06\n","\n","  # MAYNILAD\n","  bill_lessthan10 = 96.32\n","  bill_first10 = 164.16\n","  bill_next10 = 20.03\n","  bill_next20_1 = 38.09\n","  bill_next20_2 = 50.03\n","  bill_next20_3 = 58.45\n","  bill_next20_4 = 61.13\n","  bill_next50_1 = 63.93\n","  bill_next50_2 = 66.78\n","  bill_over200 = 69.60\n","\n","  consumption = final_reading - initial_reading\n","  consumption_ctr = 10\n","  counter = 10\n","  expectedBill = bill_first10\n","  if(consumption < 10):\n","    expectedBill = bill_lessthan10\n","  elif(consumption == 10):\n","    expectedBill = bill_first10\n","  else:\n","    expectedBill = bill_first10\n","    while(counter < consumption):\n","      if(consumption_ctr < 20): #next 10\n","        expectedBill += bill_next10\n","        counter += 1\n","        consumption_ctr += 1\n","      elif(consumption_ctr < 40): #next20 1\n","        expectedBill += bill_next20_1\n","        counter += 1\n","        consumption_ctr += 1\n","      elif(consumption_ctr < 60): #next20 2\n","        expectedBill += bill_next20_2\n","        counter += 1\n","        consumption_ctr += 1\n","      elif(consumption_ctr < 80): #next20 3\n","        expectedBill += bill_next20_3\n","        counter += 1\n","        consumption_ctr += 1\n","      elif(consumption_ctr < 100): #next20 4\n","        expectedBill += bill_next20_4\n","        counter += 1\n","        consumption_ctr += 1\n","      elif(consumption_ctr < 150): #next50 1\n","        expectedBill += bill_next50_1\n","        counter += 1\n","        consumption_ctr += 1\n","      elif(consumption_ctr < 200): #next50 2\n","        expectedBill += bill_next50_2\n","        counter += 1\n","        consumption_ctr += 1\n","      else:\n","        expectedBill += bill_over200\n","        counter += 1\n","        consumption_ctr += 1\n","\n","  basic_charge = expectedBill\n","  FCDA = 0.0055*basic_charge\n","  environmental_charge = 0.2*(basic_charge - FCDA)\n","  sewer_charge = 0\n","  vat = 0.12*(basic_charge-FCDA+environmental_charge+sewer_charge)\n","  before_tax = basic_charge-FCDA+environmental_charge+sewer_charge\n","  total_bill = basic_charge-FCDA+environmental_charge+sewer_charge+vat\n","  print(\"Water Consumption = \" + str(consumption) + \" cubic meters\")\n","  print(\"Basic Charge = \",basic_charge)\n","  print(\"FCDA =\", FCDA)\n","  print(\"Environmental Charge =\", environmental_charge)\n","  print(\"Sewer Charge =\", sewer_charge)\n","  print(\"ADD VAT =\", vat)\n","  print(\"Total Current Charge Before Tax =\", before_tax)\n","  print(\"TOTAL BILL =\", total_bill)\n","  return consumption, basic_charge, FCDA, environmental_charge, sewer_charge, vat, before_tax, total_bill"],"metadata":{"id":"JGSMN4z7WYCx"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copy of watermeter_prediction.ipynb","provenance":[{"file_id":"1-qcZ81TT64xEhnQmERbL3yy7gxH7wUj1","timestamp":1647608308233},{"file_id":"1PUwZmZ7KEK5TdFb4vckL4TgXC1hKHMea","timestamp":1646395129893}],"authorship_tag":"ABX9TyMxvuoj9VdsteopEffQ4MxO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}